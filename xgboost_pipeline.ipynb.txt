{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFVB7wGxJ5gD"
      },
      "source": [
        "# XGBoost para la tasa de desempleo\n",
        "\n",
        "Script para descargar, preprocesar y modelar la tasa de desempleo del Perú usando **XGBoost**."
      ],
      "id": "BFVB7wGxJ5gD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aru12xGfJ5gG"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Iterable, List, Optional, Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "import requests\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n"
      ],
      "id": "Aru12xGfJ5gG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx06P03OJ5gJ"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class XGBoostResults:\n",
        "    \"\"\"Estructura que centraliza los artefactos generados por el pipeline.\"\"\"\n",
        "\n",
        "    datasets: Dict[str, pd.DataFrame]\n",
        "    dataframe: pd.DataFrame\n",
        "    features: List[str]\n",
        "    scaler: StandardScaler\n",
        "    model: XGBRegressor\n",
        "    metrics: Dict[str, float]\n",
        "    predictions: np.ndarray\n",
        "    y_test: np.ndarray\n",
        "    test_dates: Sequence[pd.Timestamp]\n",
        "    feature_importance: pd.DataFrame\n"
      ],
      "id": "Sx06P03OJ5gJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7I7xNwCJ5gL"
      },
      "outputs": [],
      "source": [
        "def get_bcrp_series(code: str) -> pd.DataFrame:\n",
        "    \"\"\"Descarga una serie del BCRP y devuelve un DataFrame con columnas ``date`` y ``value``.\"\"\"\n",
        "\n",
        "    url = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/{code}/json/1960-01/2100-12/ing\"\n",
        "    response = requests.get(url, timeout=30)\n",
        "    if response.status_code != 200:\n",
        "        raise RuntimeError(f\"Error al obtener la serie {code}: {response.status_code}\")\n",
        "    payload = response.json()\n",
        "    entries = payload[\"periods\"]\n",
        "    df = pd.DataFrame(entries)\n",
        "    df[\"date\"] = pd.to_datetime(df[\"name\"], format=\"%b.%Y\", errors=\"coerce\")\n",
        "    df[\"value\"] = pd.to_numeric(df[\"values\"].str[0], errors=\"coerce\")\n",
        "    return df[[\"date\", \"value\"]]\n",
        "\n",
        "\n",
        "def download_series(code_map: Dict[str, str]) -> Dict[str, pd.DataFrame]:\n",
        "    \"\"\"Descarga todas las series definidas y las devuelve renombradas por su alias.\"\"\"\n",
        "\n",
        "    datasets: Dict[str, pd.DataFrame] = {}\n",
        "    for alias, code in code_map.items():\n",
        "        series = get_bcrp_series(code)\n",
        "        datasets[alias] = series.rename(columns={\"value\": alias})\n",
        "    return datasets\n",
        "\n",
        "\n",
        "def merge_series(datasets: Dict[str, pd.DataFrame], base_key: str = \"U\") -> pd.DataFrame:\n",
        "    \"\"\"Une todas las series descargadas en un único DataFrame indexado por fecha.\"\"\"\n",
        "\n",
        "    if base_key not in datasets:\n",
        "        raise KeyError(\"La serie base 'U' es obligatoria para construir el dataset\")\n",
        "    df = datasets[base_key].copy()\n",
        "    for alias, data in datasets.items():\n",
        "        if alias == base_key:\n",
        "            continue\n",
        "        df = pd.merge(df, data, on=\"date\", how=\"outer\")\n",
        "    df = df.sort_values(\"date\").set_index(\"date\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_lags(data: pd.DataFrame, column: str, lags: int) -> pd.DataFrame:\n",
        "    \"\"\"Agrega columnas con rezagos consecutivos a partir de una columna existente.\"\"\"\n",
        "\n",
        "    for lag in range(1, lags + 1):\n",
        "        data[f\"{column}_L{lag}\"] = data[column].shift(lag)\n",
        "    return data\n"
      ],
      "id": "a7I7xNwCJ5gL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ7nISRxJ5gM"
      },
      "outputs": [],
      "source": [
        "def prepare_dataframe(\n",
        "    datasets: Dict[str, pd.DataFrame],\n",
        "    lags: int = 12,\n",
        "    start_date: Optional[str] = \"2007-01-01\",\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Construye el DataFrame final listo para el modelado supervisado.\"\"\"\n",
        "\n",
        "    df = merge_series(datasets)\n",
        "    if \"pi\" in df.columns:\n",
        "        df[\"pi\"] = df[\"pi\"].interpolate()\n",
        "        df[\"inflacion\"] = df[\"pi\"].pct_change(12) * 100\n",
        "    df = df.interpolate().dropna()\n",
        "    if start_date is not None:\n",
        "        df = df[df.index >= start_date]\n",
        "    for column in [\"i\", \"inflacion\", \"E\", \"Y\", \"Xexp\"]:\n",
        "        if column in df.columns:\n",
        "            df = add_lags(df, column, lags)\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "\n",
        "def prepare_training_data(\n",
        "    df: pd.DataFrame,\n",
        "    target: str = \"U\",\n",
        "    drop_columns: Optional[Tuple[str, ...]] = (\"pi\",),\n",
        "    test_size: float = 0.2,\n",
        ") -> Tuple[List[str], np.ndarray, np.ndarray, np.ndarray, np.ndarray, StandardScaler]:\n",
        "    \"\"\"Genera los conjuntos de entrenamiento y prueba normalizados.\"\"\"\n",
        "\n",
        "    excluded = {target}\n",
        "    if drop_columns:\n",
        "        excluded.update(drop_columns)\n",
        "    features = [col for col in df.columns if col not in excluded]\n",
        "    X = df[features].values\n",
        "    y = df[target].values\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=test_size, shuffle=False\n",
        "    )\n",
        "    return features, X_train, X_test, y_train, y_test, scaler\n"
      ],
      "id": "ZZ7nISRxJ5gM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhviHmvzJ5gO"
      },
      "outputs": [],
      "source": [
        "def train_xgboost_model(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    X_test: np.ndarray,\n",
        "    y_test: np.ndarray,\n",
        "    *,\n",
        "    n_estimators: int = 600,\n",
        "    max_depth: int = 4,\n",
        "    learning_rate: float = 0.05,\n",
        "    subsample: float = 0.9,\n",
        "    colsample_bytree: float = 0.9,\n",
        "    reg_lambda: float = 1.0,\n",
        "    reg_alpha: float = 0.0,\n",
        "    random_state: int = 42,\n",
        ") -> Tuple[XGBRegressor, Dict[str, float], np.ndarray]:\n",
        "    \"\"\"Entrena un modelo ``XGBRegressor`` y devuelve métricas básicas de evaluación.\"\"\"\n",
        "\n",
        "    model = XGBRegressor(\n",
        "        objective=\"reg:squarederror\",\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        learning_rate=learning_rate,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        reg_lambda=reg_lambda,\n",
        "        reg_alpha=reg_alpha,\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
        "    predictions = model.predict(X_test)\n",
        "    metrics = {\n",
        "        \"mae\": float(mean_absolute_error(y_test, predictions)),\n",
        "        \"rmse\": float(np.sqrt(mean_squared_error(y_test, predictions))),\n",
        "        \"r2\": float(r2_score(y_test, predictions)),\n",
        "    }\n",
        "    return model, metrics, predictions\n",
        "\n",
        "\n",
        "def compute_feature_importance(model: XGBRegressor, features: Sequence[str]) -> pd.DataFrame:\n",
        "    \"\"\"Calcula la importancia de cada variable predictora según el modelo entrenado.\"\"\"\n",
        "\n",
        "    importances = model.feature_importances_\n",
        "    importance_df = pd.DataFrame({\"feature\": list(features), \"importance\": importances})\n",
        "    importance_df = importance_df.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
        "    return importance_df\n",
        "\n",
        "\n",
        "def build_evaluation_frame(results: XGBoostResults) -> pd.DataFrame:\n",
        "    \"\"\"Construye un DataFrame con los valores reales y estimados del conjunto de prueba.\"\"\"\n",
        "\n",
        "    evaluation_df = pd.DataFrame(\n",
        "        {\n",
        "            \"date\": pd.to_datetime(results.test_dates),\n",
        "            \"real\": results.y_test,\n",
        "            \"estimado\": results.predictions,\n",
        "        }\n",
        "    )\n",
        "    evaluation_df = evaluation_df.sort_values(\"date\").reset_index(drop=True)\n",
        "    return evaluation_df\n",
        "\n",
        "\n",
        "\n",
        "def plot_actual_vs_predicted(\n",
        "    results: XGBoostResults,\n",
        "    *,\n",
        "    ax: Optional[\"plt.Axes\"] = None,\n",
        "    title: str = \"Tasa de desempleo: real vs estimado\",\n",
        ") -> \"plt.Axes\":\n",
        "    \"\"\"Genera un gráfico con las series reales y estimadas del conjunto de prueba.\"\"\"\n",
        "\n",
        "    evaluation_df = build_evaluation_frame(results)\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    else:\n",
        "        fig = ax.figure\n",
        "    ax.plot(evaluation_df[\"date\"], evaluation_df[\"real\"], label=\"Dato real\", marker=\"o\")\n",
        "    ax.plot(\n",
        "        evaluation_df[\"date\"],\n",
        "        evaluation_df[\"estimado\"],\n",
        "        label=\"Dato estimado\",\n",
        "        marker=\"o\",\n",
        "    )\n",
        "    ax.set_xlabel(\"Fecha\")\n",
        "    ax.set_ylabel(\"Tasa de desempleo\")\n",
        "    ax.set_title(title)\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m\"))\n",
        "    fig.autofmt_xdate()\n",
        "    return ax\n",
        "\n",
        "\n",
        "def run_xgboost_pipeline(\n",
        "    code_map: Dict[str, str],\n",
        "    start_date: str = \"2007-01-01\",\n",
        "    test_size: float = 0.2,\n",
        "    lags: int = 12,\n",
        "    drop_columns: Optional[Iterable[str]] = (\"pi\",),\n",
        ") -> XGBoostResults:\n",
        "    \"\"\"Orquesta la descarga, preparación y modelado usando XGBoost.\"\"\"\n",
        "\n",
        "    datasets = download_series(code_map)\n",
        "    df = prepare_dataframe(datasets, lags=lags, start_date=start_date)\n",
        "    (\n",
        "        features,\n",
        "        X_train,\n",
        "        X_test,\n",
        "        y_train,\n",
        "        y_test,\n",
        "        scaler,\n",
        "    ) = prepare_training_data(\n",
        "        df, target=\"U\", drop_columns=tuple(drop_columns) if drop_columns else None, test_size=test_size\n",
        "    )\n",
        "    model, metrics, predictions = train_xgboost_model(X_train, y_train, X_test, y_test)\n",
        "    feature_importance = compute_feature_importance(model, features)\n",
        "    test_dates = df.index[-len(y_test) :]\n",
        "    return XGBoostResults(\n",
        "        datasets=datasets,\n",
        "        dataframe=df,\n",
        "        features=features,\n",
        "        scaler=scaler,\n",
        "        model=model,\n",
        "        metrics=metrics,\n",
        "        predictions=predictions,\n",
        "        y_test=y_test,\n",
        "        test_dates=test_dates,\n",
        "        feature_importance=feature_importance,\n",
        "    )\n"
      ],
      "id": "RhviHmvzJ5gO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEIxkMszJ5gQ"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    SERIES_CODES = {\n",
        "        \"U\": \"PN38063GM\",\n",
        "        \"i\": \"PD04722MM\",\n",
        "        \"pi\": \"PN01271PM\",\n",
        "        \"E\": \"PN01246PM\",\n",
        "        \"Y\": \"PN38082AM\",\n",
        "        \"Xexp\": \"PD38045AM\",\n",
        "    }\n",
        "    results = run_xgboost_pipeline(SERIES_CODES)\n",
        "    print(\"Métricas del modelo XGBoost:\")\n",
        "    for key, value in results.metrics.items():\n",
        "        print(f\"- {key.upper()}: {value:.4f}\")\n",
        "    print(\"\\nVariables predictoras:\")\n",
        "    for feature in results.features:\n",
        "        print(f\"- {feature}\")\n",
        "    print(\"\\nInfluencia de las variables (importancia):\")\n",
        "    print(results.feature_importance.to_string(index=False))\n",
        "    print(\"\\nGenerando el gráfico comparativo de la tasa de desempleo...\")\n",
        "    ax = plot_actual_vs_predicted(results)\n",
        "    ax.figure.tight_layout()\n",
        "    output_path = \"xgboost_unemployment_actual_vs_predicted.png\"\n",
        "    ax.figure.savefig(output_path, dpi=150)\n",
        "    plt.show()\n",
        "    plt.close(ax.figure)\n",
        "    print(f\"Gráfico guardado en: {output_path}\")\n"
      ],
      "id": "kEIxkMszJ5gQ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}